# ğŸ“¡ Telco Churn MLOps Project

[![CI-CD](https://github.com/rawad-yared/telco-churn-mlops/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/rawad-yared/telco-churn-mlops/actions/workflows/ci-cd.yml)

End-to-end churn prediction project using the **IBM Telco Customer Churn** dataset:

- Reproducible data & feature pipelines  
- Model training & evaluation with scikit-learn  
- Experiment tracking with MLflow  
- Containerized deployment with Docker  
- FastAPI API for online inference  
- Streamlit dashboard for interactive predictions  

â¸»

ğŸ§­ 1. Project Overview

A full end-to-end MLOps pipeline for predicting telecom customer churn using the IBM Telco Customer Churn dataset.

The goal is to classify whether a customer will churn based on contract type, services, tenure, billing patterns, and demographics.

ğŸ”§ Tech Stack:
	â€¢	Python 3.12, pandas, scikit-learn
	â€¢	MLflow for experiment tracking
	â€¢	FastAPI for online inference
	â€¢	Streamlit for dashboarding
	â€¢	Docker for containerization
	â€¢	GitHub Actions for CI/CD
	â€¢	GitHub Container Registry (GHCR) for image hosting
	â€¢	Render.com for cloud deployment

ğŸ” MLOps Pipeline (High-Level)

Git push â†’ GitHub Actions â†’ Train â†’ Build â†’ Test â†’ Push Image â†’ Render Deploy â†’ Live API



---


## ğŸ—‚ï¸ 2. Repository Structure


```bash
telco-churn-mlops/
â”œâ”€ app/
â”‚  â”œâ”€ fastapi_app.py         # FastAPI serving API
â”‚  â””â”€ streamlit_app.py       # Optional Streamlit UI
â”œâ”€ src/
â”‚  â”œâ”€ data/
â”‚  â”‚  â””â”€ load_data.py        # Load + clean dataset
â”‚  â”œâ”€ features/
â”‚  â”‚  â””â”€ build_features.py
â”‚  â””â”€ models/
â”‚     â”œâ”€ train_model.py      # Model training, MLflow logging
â”‚     â””â”€ predict_model.py     # Schema-aligned inference pipeline
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”‚  â””â”€ Telco_customer_churn.xlsx   # Dataset (tracked in Git)
â”‚  â””â”€ processed/                      # Generated
â”œâ”€ models/                             # Generated (artifacts)
â”œâ”€ mlruns/                             # Local MLflow logs
â”œâ”€ Dockerfile
â”œâ”€ requirements.txt
â”œâ”€ Makefile
â””â”€ README.md


## âš™ï¸ 3. Setup Instructions

### ğŸª„ Clone the repository

```bash
git clone https://github.com/rawad-yared/telco-churn-mlops.git
cd telco-churn-mlops

ğŸ§± Create and activate a virtual environment

python -m venv .venv
source .venv/bin/activate      # macOS/Linux
# .venv\Scripts\activate       # Windows

ğŸ“¦ Install dependencies

pip install --upgrade pip
pip install -r requirements.txt


â¸»

ğŸ“Š 4. Data Setup

The dataset is already included and tracked:

data/raw/Telco_customer_churn.xlsx


â¸»

ğŸ§© 5. Automated MLOps Pipeline (CI/CD)

Once you clone the repository and install dependencies, you do not need to run the pipeline manually.
This project uses a full CI/CD workflow with:
	â€¢	GitHub Actions (CI)
	â€¢	GitHub Container Registry (GHCR)
	â€¢	Render (CD)

Every time you push to the main branch, the entire workflow runs end-to-end.

Below is how to set it up.

â¸»

ğŸ”§ Step 1 â€” Create TWO Render Services

You must create two Web Services on Render:

â¸»

1ï¸âƒ£ FastAPI Production API
	â€¢	Render â†’ New â†’ Web Service
	â€¢	Choose â€œDeploy an existing imageâ€
	â€¢	Use image (will be created automatically on first push):

ghcr.io/<your-username>/telco-churn-mlops:latest


	â€¢	Start Command:

uvicorn app.fastapi_app:app --host 0.0.0.0 --port $PORT


	â€¢	Save the service â†’ copy the Service ID

â¸»

2ï¸âƒ£ Streamlit Dashboard (UI)
	â€¢	Create a second Web Service
	â€¢	Use the same GHCR image
	â€¢	Start Command: leave it empty

â¸»

ğŸ” Step 2 â€” Add GitHub Secrets (Required for CI/CD)

Go to:
GitHub â†’ Repo â†’ Settings â†’ Secrets â†’ Actions

Create these secrets:

Secret	What it is
RENDER_API_KEY	From Render â†’ Account â†’ API Keys
RENDER_SERVICE_ID	Streamlit Service ID
RENDER_FASTAPI_SERVICE_ID	FASTAPI Service ID

These allow GitHub Actions to deploy automatically after building the image.

â¸»

ğŸš€ Step 3 â€” Push to GitHub (CI/CD Runs Automatically)

Once the secrets and Render services are configured, you never run the pipeline manually again.

Simply do:

git add .
git commit -m "update"
git push

GitHub Actions will automatically:

CI Phase
	1.	Install dependencies
	2.	Load Telco dataset
	3.	Train Logistic Regression + Random Forest
	4.	Log metrics with MLflow
	5.	Save the best model
	6.	Build Docker image
	7.	Health-check the image locally in CI
	8.	Push image â†’ GHCR

CD Phase
	9.	Trigger Render deploy for FastAPI
	10.	(Optional) Trigger Render deploy for Streamlit
	11.	Render pulls the new image
	12.	Your updated API + Dashboard are live automatically

â¸»

ğŸŒ Step 4 â€” Visit Your Live Services

After the first successful push:

FastAPI (production)

https://<your-fastapi-service>.onrender.com/docs

Streamlit dashboard

https://<your-streamlit-service>.onrender.com

These update automatically on every push

